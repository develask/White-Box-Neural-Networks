y los primeros sobre la tarea del reconocimiento de voz a de la década de los primeros basados en y capaces de reconocer palabras aisladas dentro de un de unas palabras a partir de la década de el uso de para desarrollar sistemas de reconocimiento de voz en esa misma década se los primeros reconocedores de habla continua en la década de los se a aplicar de reconocimiento de para resolver el problema del reconocimiento de voz en las de los 80 y los resultados en el ámbito de reconocimiento de voz mediante sistemas basados en modelos en en modelos ocultos de markov en estos últimos años el uso de redes neuronales artificiales se ha en todos los del reconocimiento de debido en gran medida al desarrollo de con gran capacidad capacidad de y al a un a gran cantidad de datos con los que entrenar estas redes a lo largo de este trabajo se de forma la de los reconocedores de voz basados en modelos generativos en se analizarán dos sistemas los sistemas basados en modelos ocultos de markov y mezclas de gaussianas y los modelos híbridos entre modelos ocultos de markov y redes neuronales para ello se realizando una al problema del reconocimiento de voz después se analizarán de forma general modelos de mezclas de gaussianas los modelos ocultos de markov y las redes neuronales finalmente se la herramienta kaldi con la se experimentos para y analizar las características de los distintos sistemas de reconocimiento de voz en nos en el de las redes neuronales de los reconocedores de voz si a un reconocedor de voz desde el punto de más posible una capaz de una señal acústica de voz en su correspondiente transcripción aún así es lograr que una señal acústica a la secuencia de palabras que el hablante haciendo uso de sus y su de hecho los humanos capaces de reconocer siempre las palabras que y que una cantidad de tiempo a la tarea de la distintos de entre años y de años se suele la tarea de reconocimiento de voz como un problema de dada una señal acústica encontrar la secuencia de palabras más probable es decir donde es el conjunto de todas las posibles secuencias de palabras en general existen dos de realizar esta la primera es intentar calcular directamente la probabilidad en este caso de modelos la otra es dividir el problema utilizando el de en la ecuación bayes se ha el ya que solo al valor de la probabilidad no a la secuencia óptima de palabras de acuerdo a la ecuación bayes calcular las probabilidades y para realizar la los sistemas que este son como sistemas generativos todos los reconocedores desarrollados en este trabajo son de este tipo de en nos en su funcionamiento el cálculo de las probabilidades es tarea de la modelización acústica mientras que para el de se modelos de lenguaje en la figura se muestra un esquema general del funcionamiento de los reconocedores de voz generativos en la parametrización y se describirán los parametrización de la señal acústica modelos acústicos y modelos de lenguaje que se pueden observar en la figura el problema de la decodificación se analizará en distintas de los estructuras reconocedores y kaldi esquema general de los reconocedores de voz generativos parametrización de la señal acústica hasta ahora hemos de como la señal acústica que estamos para conseguir su transcripción la señal acústica representa las en la del en este caso por el hablante a lo largo del tiempo es necesario que en la mayoría de reconocedores de voz los desarrollados en este trabajo no se directamente con esta señal lo más común es para ello se en ventanas de tiempo las cuales se pueden y cada una de las ventanas se para ser con un vector es decir no es la señal acústica en sino la secuencia de los vectores de parámetros o vectores acústicos que la al una señal acústica hay que tener en cuenta el tamaño de las ventanas y la transformación que se va aplicar a cada una de ellas para el tamaño de las ventanas es importante primero qué transformación se va a utilizar y por qué transformación para conseguir el vector de parámetros asociado a un de la señal acústica para entre todos los sonidos que capaces de los humanos la de las de a distintas frecuencias aproximadamente dentro del de 20 a 20 pero no el sonido de forma lineal respecto a la si se la diferencia de frecuencia entre como que esta no es constante capaces de en la frecuencia de señales a frecuencias mientras que a frecuencias más tiene que más la frecuencia para que un cambio en el por ejemplo ésta es la de que la entre los de una no sea todo el igual a lo del en y la escala mel el nombre mel de la palabra en la cual los de altura son la relación entre y unidades de la escala mel es así que los vectores que van a representar cada ventana de audio información sobre la de la señal a distintas frecuencias frecuencias a constante en la escala mel vectores están por los coeficientes en las frecuencias de mel mfcc por sus siglas en inglés en reconocimiento de voz se suelen utilizar coeficientes que contienen información sobre las frecuencias en las que los humanos sonidos el algoritmo para calcular los mfcc consta de las siguientes se pueden añadir pero con estas se la del el audio de acuerdo al tamaño y de ventana aplicar la función de ventana la más común es la ventana esto la de en la computar la de para conseguir el de nuestro de señal calcular la en distintos de frecuencias de igual tamaño forma y en la escala mel calcular el de las en la la razón de este paso es que no solo la de las es sino también la de la del sonido finalmente aplicar la a los de las el resultado son los mfcc las parametrizaciones mfcc son muy en el ámbito del reconocimiento de voz durante este trabajo utilizaremos parametrizaciones mfcc en distintas ocasiones pero también otras parametrizaciones las cuales de los vectores de parámetros mfcc estas serán en la sección tamaño de las ventanas para la señal acústica las ventanas han de ser suficientemente como para información sobre el sonido que se ha producido en ese de tiempo como se ha en la sección mfcc la información que los humanos de una señal acústica está en el de señal si el tamaño de ventana muy el resultado de la de la señal que ha dentro de la ventana no será demasiado porque la se con muy por otra parte nos que el tamaño de ventana suficiente como para no información de distintos sonidos si que cada ventana información de solo un sonido el nos dará información sobre el fonema que estamos analizando por tanto en los reconocedores de voz desarrollados se ha por ventanas y de así que las ventanas se en este caso estos dos valores son muy a la de realizar el cálculo de los mfcc modelos acústicos los modelos acústicos son de los vectores de parámetros en la sección parametrización la modelización acústica se de computar la probabilidad de la ecuación bayes para ello que con modelos acústicos capaces de los sonidos correspondientes las unidades fonéticas del habla y con un léxico que la pronunciación de cada palabra que a reconocer léxico podemos que el léxico es un si una palabra en el léxico éste nos dará su pronunciación es decir la secuencia de fonemas correspondiente a la palabra que el léxico ha de tener en cuenta que puede más de una forma de una palabra en ese caso el léxico nos todas las posibles y la probabilidad de cada una de ellas los reconocedores de voz desarrollados en este trabajo tienen como objetivo reconocer secuencias de palabras en castellano el castellano es un en lo que a la transcripción de palabras a fonemas se sobre todo si lo con como el inglés o el con un conjunto de reglas de pronunciación podemos deducir la secuencia de fonemas que a cada palabra en vez de tener que utilizar de pronunciación con estas reglas no es necesario mencionar que distintas palabras pueden tener una misma pronunciación por ejemplo y nuestro objetivo es calcular al léxico podemos dividir una secuencia de palabras en la secuencia de fonemas correspondiente simplemente las secuencias de fonemas cada palabra por tanto podemos desarrollar la probabilidad donde es el conjunto de todas las secuencias de fonemas o unidades la ecuación el caso general de las es decir tiene en cuenta las distintas posibles de una palabra y la probabilidad de cada una de ellas en nuestro caso cada palabra tiene una y solo una pronunciación posible así solo una pronunciación en el conjunto que presente una probabilidad no y además igual a uno si esa pronunciación como en este punto podríamos cómo calcular es decir cómo modelizar secuencias de unidades fonéticas pero como al de esta sección lo más común es un paso más antes de realizar la modelización los fonemas en fonemas trifonemas durante este trabajo se analizarán tanto los sistemas basados en fonemas como en trifonemas fonemas del contexto los humanos de forma distinta los fonemas en función de cual ha sido el anterior fonema y de cual va a ser el siguiente el uso de trifonemas permite tener en cuenta este y mejorar así el rendimiento del reconocedor de voz un trifonema es una representación de un fonema mediante tres fonemas se utiliza el central para el fonema que vamos a representar el para el fonema anterior y el para el posterior por ejemplo la palabra casa se de la siguiente forma en fonemas y trifonemas con nos a la secuencia de fonemas o trifonemas y con a la de fonema anterior o si utilizamos un reconocedor basado en trifonemas podemos los resultados de las ecuaciones y para ello tener en cuenta que dada una secuencia de fonemas existe una única secuencia de trifonemas equivalente como se puede observar en el ejemplo anterior también es similar al caso de nuestro léxico en el que dada una secuencia de palabras se consigue una única secuencia de fonemas en la ecuación se han utilizado y para hacer al caso más general el correspondiente a la ecuación si se utiliza un léxico que solo contiene una pronunciación por palabra se puede por y por tanto si vamos a utilizar un sistema basado en fonemas o trifonemas ahora tarea es crear modelos acústicos estos modelos nos los vectores de parámetros con las unidades fonéticas que en el caso de los modelos generativos este caso indica calcular la probabilidad sistema basado en fonemas o sistema basado en trifonemas a día de lo más común es utilizar modelos ocultos de markov hmm por sus siglas en inglés basados en mezclas de gaussianas gmm por sus siglas en inglés o modelos híbridos entre hmm y redes neuronales dnn por sus siglas en inglés ambos modelos serán durante este trabajo en los hmm y se el funcionamiento general de los modelos ocultos de markov y de redes neuronales respectivamente en la sección reconocedores se analizará como aplicar los hmm y las dnn para crear modelos acústicos se describirán los modelos gmm-hmm sección gmm-hmm y los híbridos dnn-hmm sección dnn-hmm modelos de lenguaje los modelos de lenguaje nos calcular la probabilidad a de la ecuación bayes es decir un modelo de lenguaje una probabilidad a una secuencia de palabras existen distintos de modelos de lenguaje los más son los n que también son unos de los más se en la de que la probabilidad de una palabra solo depende de misma y de las palabras anteriores en el caso de y la probabilidad de cada palabra solo depende de la palabra en general la probabilidad de la secuencia será aproximadamente la siguiente: cada probabilidad puede ser de forma a partir de un corpus de entrenamiento simplemente y normalizando veces a la palabra después de la secuencia si representa la cantidad de de una secuencia en el esta forma de computar las probabilidades tiene un problema problema que aumenta cuanto mayor es el orden del modelo de lenguaje n menor es el tamaño del corpus de entrenamiento si un modelo de lenguaje utilizando solo las ecuaciones y la probabilidad de secuencias de palabras no durante el entrenamiento sería aunque cada palabra haya sido esta aproximación es por ejemplo puede que las secuencias mi casa y mi casa pero no la secuencia mi casa aún así demasiado decir que la probabilidad de mi casa es la más común es realizar un smoothing así secuencias que no sido en el corpus tener probabilidades no en el modelo de lenguaje en la práctica y en este trabajo los n más utilizados son los que tienen los trigramas modelos ocultos de markov y modelos de mezclas de gaussianas en este capítulo se analizarán de forma los modelos ocultos de markov hmm como se en la sección hmm en la tarea de reconocimiento de voz los hmm de los modelos de mezclas de gaussianas gmm por lo que se describirán éstas de forma al de los hmm modelos de mezclas de gaussianas la distribución gaussiana es una distribución de probabilidad utilizada en en el caso del reconocimiento de voz se suelen para modelizar los vectores de parámetros después de la parametrización de una señal acústica una distribución gaussiana para una sola variable está mediante la siguiente donde es la media y la varianza las distribuciones gaussianas se pueden a un mediante la siguiente función donde es el vector de de dimensión y la matriz de de dimensión en ocasiones por ejemplo en reconocimiento de voz puede que la variable o vector sea demasiado como para que una sola distribución gaussiana lo en esos casos se puede la distribución gaussiana por una mezcla de varias distribuciones gaussianas si es el número de gaussianas en la mezcla y el peso de cada gaussiana la gmm será la siguiente: en la figura se muestra un ejemplo de una gmm representación gráfica de un ejemplo de una mezcla de dos gaussianas en un fuente: en el contexto de distribuciones por mezclas de gaussianas se la función ésta indica si el vector esta asociado a la gaussiana con índice de la gmm es decir modelos ocultos de markov los modelos ocultos de markov son modelos desarrollados por y a de la década de éstos son una extensión de las o modelos de markov por markov en ambos sirven para modelizar sistemas que de memoria es decir sistemas en los que la probabilidad del siguiente estado solo depende del estado actual propiedad de markov la diferencia está en que en las de markov los estados son mientras que en los hmm estos estados están ocultos esto decir que a diferencia de las de markov en los hmm cada salida del sistema no está directamente a un estado cada estado del hmm tiene asociado una o un conjunto de probabilidades o de probabilidades para cada posible salida del sistema como ejemplo supongamos que queremos modelizar el tiempo en bilbao que el tiempo no durante cada día y que los solo pueden ser o podríamos una y estimar las probabilidades de cada teniendo en cuenta el tiempo que el día anterior probabilidades de transición el resultado ser la cadena de markov que se muestra en la figura representación gráfica del ejemplo de cadena de markov no se han las probabilidades iniciales para no el esquema para un hmm supongamos ahora que a y por tanto no podemos conocer directamente el tiempo en bilbao en cambio podemos con un amigo de bilbao que nos cuenta lo que éste ha hecho durante el de o modelos ocultos de markov conocemos a nuestro amigo lo que en este contexto que conocemos las probabilidades de que de o se en función del tiempo probabilidades de emisión con esta información es posible modelizar el tiempo en bilbao en a las de nuestro amigo mediante el hmm en la figura representación gráfica del ejemplo de hmm no se han las probabilidades iniciales hay que decir que es posible tener un número de salidas por ejemplo nuestro amigo nos decir la media durante el día en vez de qué ha hecho en ese caso las probabilidades de emisión se por de probabilidad aún más es posible que nuestro amigo no solo nos un al día sino un vector de datos por la media la y el de la así en cada estado del hmm una probabilidad de emisión de un vector componentes en este punto ya se puede que en el caso del reconocimiento de voz las observaciones serán los vectores de parámetros descritos en la sección parametrización y que los estados del hmm de forma los fonemas o trifonemas que estamos intentando reconocer además es la de vectores que información sobre la señal acústica con la de nuestro amigo de bilbao la y la nos van a más información sobre el estado que el de la en la sección reconocedores la topología de los hmm utilizados en los reconocedores de voz y cómo se las probabilidades de emisión de cada componente de los vectores en cada estado de un hmm en las sección decviterbi analizaremos los algoritmos para utilizar los hmm para es necesario la notación para definir un hmm y las observaciones que se van a intentar modelizar las posibles salidas observaciones pueden ser tanto como continuas y tanto como n lo más común es que las observaciones sean símbolos discretos o vectores de variables continuas una secuencia de observaciones como donde es el tamaño de la secuencia si las observaciones son símbolos discretos cada observación será una de las posibles salidas del hmm si por el las observaciones son vectores de variables continuas cada componente de ese vector en general cualquier valor se puede definir la estructura de un hmm mediante las distribuciones de probabilidades y es la matriz de probabilidades de transición representa las probabilidades de emisión en un estado y contiene las probabilidades iniciales de cada estado [• ] representa la probabilidad de transición del estado al estado siendo si es la cantidad de estados del hmm [• ] representa la probabilidad de emisión de la posible salida en el estado si las salidas son vectores de variables continuas será un de probabilidad si las observaciones son símbolos discretos las probabilidades de emisión de cada uno de símbolos de salida posibles [• ] representa la probabilidad de comenzar en el estado una cadena de markov se puede un caso de un hmm en el que en cada estado la probabilidad de emisión es 1 para un dado y 0 para todos los métodos en los hmm a continuación se las o métodos para poder utilizar los hmm en primer lugar necesitamos cómo computar la secuencia óptima de estados que una secuencia de observaciones dada este problema se conoce como decodificación en el caso de la en bilbao la decodificación nos conocer ha sido el tiempo en bilbao durante los en los que nuestro amigo nos ha estado datos por otro lado tenemos que crear el modelo este proceso se conoce como entrenamiento el problema se de la siguiente dada una topología de hmm y una secuencia de observaciones los parámetros del hmm de forma que se la probabilidad de que la secuencia de observaciones haya sido por el hmm en nuestro ejemplo simple las probabilidades de transición entre y y en el caso más simple las probabilidades de que nuestro amigo de o en función del estado del tiempo existen distintos algoritmos para resolver o resolver aproximadamente los problemas de la decodificación y del entrenamiento nos en los algoritmos durante este trabajo decodificación mediante el algoritmo de viterbi una forma de resolver el problema de la decodificación es aplicar la dada una secuencia de observaciones calcular todas las secuencias de estados posibles y sus probabilidades y secuencia con mayor probabilidad el problema de este es que es demasiado el algoritmo de viterbi es más para resolver el problema de la decodificación ya que calcula la secuencia óptima de estados si es la secuencia de observaciones el algoritmo de viterbi la secuencia de estados más probable con los siguientes computar la probabilidad de comenzar cada estado teniendo en cuenta las probabilidades iniciales y las probabilidad de emisión de la primera observación de cada estado por cada observación con la probabilidad de en cada estado en el instante llamaremos a esta probabilidad y el estado en el instante anterior a dicho estado llamaremos al estado anterior en podemos haber al estado en el instante desde cualquier estado en el instante se como estado anterior que presente la mayor probabilidad teniendo en cuenta la probabilidad de haber estado dicho estado y haber al estado actual ecuación así la probabilidad de en el estado actual la probabilidad de haber estado en el estado anterior haber al estado actual y haber la observación ecuación realizando el paso 2 desde hasta las probabilidades de cada estado en el instante y el estado anterior a cada uno como último estado que presente una mayor probabilidad ecuación esa probabilidad será la probabilidad total de la secuencia más probable ecuación secuencia óptima como hemos el estado anterior a cada estado podemos de forma la secuencia aplicando la mostrada en la ecuación desde hasta entrenamiento mediante el procedimiento de viterbi el entrenamiento mediante el procedimiento de viterbi o entrenamiento de viterbi es un proceso que permite ajustar los parámetros de un hmm para la probabilidad de que el hmm haya producido una o un conjunto de secuencias de observación con esta secuencia o conjunto de secuencias se datos de entrenamiento o datos de aprendizaje como su nombre indica este proceso esta basado en el algoritmo de viterbi sección decviterbi el entrenamiento consta de los siguientes hay que definir cuales serán los parámetros del hmm y antes de comenzar el entrenamiento en función de la se pueden de forma todos los parámetros alineación cada secuencia de datos de aprendizaje es decir encontrar la secuencia óptima de estados que correspondiente para cada secuencia de datos de aprendizaje la alineación se consigue mediante el algoritmo de viterbi sección decviterbi en el caso del reconocimiento de voz en la primera iteración se realiza una alineación a cada estado el mismo número de observaciones una vez tenemos alineadas las secuencias de datos de aprendizaje las probabilidades de transición de acuerdo a la frecuencia en las que éstas se han donde es la probabilidad de transición del estado al estado el número de del estado al estado en las secuencias alineadas en el paso 2 y el número total de desde el estado a cualquier estado en las secuencias alineadas las probabilidades iniciales se pueden computar de forma similar y normalizando veces se ha en cada estado aún así en el caso del reconocimiento de voz no suele tener demasiado el cálculo de estas probabilidades ya que por el léxico y el modelo de lenguaje las probabilidades de emisión se de forma distinta en función de si las observaciones son o continuas si son las probabilidades se y normalizando veces se ha cada salida posible en cada donde es la probabilidad de emisión del en el estado la cantidad de observaciones de la salida alineadas con el estado durante el entrenamiento y la cantidad total de observaciones alineadas con el estado durante el entrenamiento si estamos vectores de variables continuas mediante mezclas de gaussianas sección gmm las se calculan mediante las y cada vector de de cada gaussiana con índice de cada estado se haciendo la media entre todos las observaciones del entrenamiento a cada una de gaussianas donde la función será 1 si y solo si el vector está asociado a la gaussiana con índice del estado la matriz de se puede estimar una vez que tenemos el vector de finalmente podemos calcular los pesos de cada gaussiana en función de la cantidad de observaciones a cada una de ellas y la cantidad de vectores con el estado durante el entrenamiento redes neuronales las redes neuronales o redes neuronales artificiales o por sus siglas en inglés son un de que sirven para información están en el funcionamiento de las neuronas y las del con una estructura las redes neuronales son funciones es decir son capaces de computar cualquier función y los primeros modelos de las redes neuronales biológicas en desde se han desarrollando tanto los modelos de redes neuronales como los algoritmos relacionados con aún así el de las redes neuronales no se ha dado hasta esta última debido al gran número de parámetros que hay que ajustar para utilizar redes neuronales para resolver problemas como el reconocimiento de los de para con redes neuronales no en la mayoría de casos la mejora en las en estos últimos años y el uso de gpus para realizar cálculos en paralelo han el uso de las redes neuronales para como el reconocimiento de voz reconocimiento de en las redes neuronales están por un conjunto de unidades neuronas y por las entre estas neuronas neuronas las neuronas son las de computar funciones dentro de una red neuronal una neurona consta de los siguientes [• ] una o más variables de entrada nos a estas entrada con el vector siendo el número de entradas a la neurona [• ] un peso por variable de entrada podemos representar estos pesos con el siguiente vector cada peso corresponde a la variable de entrada [• ] un bias se como [• ] una salida [• ] una función de propagación o transferencia que las entradas los pesos y el bias para conseguir la entrada a la función de activación ; [• ] una función de activación que permite calcular la activación de la neurona en función de la salida de la función de propagación en la figura neurona podemos una representación gráfica de una neurona representación gráfica de una neurona los pesos y el bias los pesos la de cada entrada a la neurona el bias indica cómo de fácil es que una neurona se esto está basado en el funcionamiento de las neuronas biológicas las neuronas biológicas se un si a su entrada las neuronas biológicas tienen una única entrada sería su equivalente en el modelo hay un mayor a un el bias es por tanto la del en el ámbito de reconocimiento de se suelen las salidas de las neuronas como de características de la muestra que se está así si que una neurona indica una dada los pesos cómo de está cada entrada con la y el bias cómo de fácil es funciones de propagación y de activación en cuanto a las funciones de propagación se suele por la suma de las entradas con pesos y del bias durante este trabajo todas las funciones de propagación serán de este tipo es decir también es que a una neurona le una única función de propagación pero es posible que una neurona la salida de más de una función de propagación en ese caso la función de activación no será una función de una variable sino de varias variables tantas como funciones de propagación las cuales con el vector no un solo bias por neurona y un solo peso por entrada sino tantos como funciones de propagación en la figura se muestra una representación gráfica de este tipo de neurona analizaremos dos ejemplos más durante esta sección representación gráfica de una neurona con dos funciones de propagación las funciones de propagación y de activación utilizadas en las redes neuronales que las neuronas artificiales se más o menos como las neuronas biológicas una diferencia es que mientras la salida de las neuronas biológicas es más bien o no las salidas de las neuronas artificiales son continuas en nuestro caso son funciones crecientes con todas sus variables porque tanto las funciones de propagación como de activación son crecientes es decir cuanto sean las entradas y sus correspondientes pesos y menor sea el o mayor sea el bias mayor será la salida otra propiedad de las neuronas es que la función de activación suele tener una salida acotada con estas tres funciones continuas crecientes y se durante el entrenamiento y se una interpretación de la salida de las neuronas a continuación introduciremos distintas funciones de activación utilizadas a lo largo de este trabajo tangente hiperbólica un ejemplo muy común de función de activación es la tangente hiperbólica ecuación como se puede en la figura la tangente hiperbólica es una función y una salida acotada entre y gráfica de la tangente hiperbólica función la función o ecuación tiene la misma forma que la tangente hiperbólica pero está acotada entre y figura gráfica de la función de hecho la es una versión de la tangente hiperbólica ecuación función relu a continuación dos funciones de activación muy diferentes a la tangente hiperbólica y a la las funciones relu y pnorm la diferencia más es que estas funciones no están aunque ambas son crecientes y continuas la salida de la función relu del inglés linear será igual a la entrada si ésta es y si la entrada es ecuación figura gráfica de la función relu el hecho de que la función relu no sea acotada por un lado tiene la de que una red neuronal basada en esta función será más de entrenar por otro lado las salidas muy pueden problemas de durante el entrenamiento este problema se normalizando la salida de estas neuronas con métodos que se describirán en la sección función pnorm como ejemplo de las neuronas que procesan la salida de más de una función de propagación tenemos las neuronas su nombre de la función de activación que la función ésta permite calcular la entre salidas de distintas funciones de propagación ecuación donde es el vector que contiene la salida de las funciones de propagación es decir las de las entradas a la neuronas con distintos pesos y y es el orden de la normalización en la figura se muestra una gráfica de la función pnorm para dos variables y con gráfica de la función pnorm para dos variables el valor de se ha en al igual que con la función relu aunque la función es continua y su salida puede ser cualquier número por tanto en este caso es también necesario la salida de las neuronas función softmax durante este trabajo siempre utilizaremos las redes neuronales como de probabilidad la red tantas neuronas en la última capa o capa de salida como clases entre las que estamos intentando los vectores de entrada la salida de cada neurona de la capa de salida se como la probabilidad de que un vector de entrada a una de las posibles clases hay que decir que para hacer una interpretación de la salida es común aunque no necesario que las salidas de todas las neuronas de la capa de salida entre 0 y 1 y que la suma de todas ellas sea 1 existen distintos métodos de lograr una salida de estas características uno de los más utilizados es que la función de activación de la última capa sea la función softmax la función softmax el la salida de la función de transferencia a cada neurona en función de la suma de los de las salida de las funciones de transferencia correspondientes al de neuronas de la capa ecuación softmax donde es la función de activación a la neurona y es el vector que contiene las de las entradas pesos y bias correspondientes a cada una de las neuronas de la capa de salida por tanto la función de activación softmax la salida de las neuronas en función de las salidas de varias funciones de propagación al igual que las neuronas del tipo pnorm estructura de las redes neuronales redes feedforward para construir una red neuronal capaz de resolver problemas es necesario un número de neuronas a la de realizar las son utilizadas las estructuras por capas feedforward en una red feedforward las neuronas se en distintas capas de forma que las salidas de las neuronas de una capa se a las entradas de todas o varias las neuronas de la capa posterior la razón de las neuronas en capas es que así entrenar las redes con los algoritmos que describiremos en la sección trainnn para calcular el vector de salida correspondiente a un vector de entrada de una red neuronal feedforward conocer todos los pesos y bias de todas las neuronas de la red y ser capaz de computar todos el cálculo de la salida es las salidas de la primera capa en función de las entradas de la red y de los parámetros de las neuronas de la primera capa mediante las funciones de propagación y activación después las salidas de la segunda capa en función de las salidas de la primera capa de la misma forma y el mismo procedimiento hasta conseguir el vector de salida el vector que las salidas de las neuronas de la última capa es decir la salida de una red neuronal en capas se hacia la entrada mediante los de funciones de propagación y las funciones de activación de cada capa para describir este proceso supongamos que tenemos una red neuronal formada por capas tal y como se muestra en la figura representación gráfica de una red neuronal feedforward que la primera capa mostrada en los ejemplo no es una capa de neuronas como tal simplemente se utiliza para representar las entradas a la red la primera capa de neuronas que realiza cálculos es por tanto la segunda cada capa el nombre de este índice de la palabra está formada por un bloque de funciones de propagación y por una función de activación por neurona el bloque de funciones de propagación el vector de salida de la capa anterior a la entrada de las funciones de activación de la capa de esta cantidad de funciones de propagación como la dimensión de entrada de la capa en este número no ha de ser igual al número de neuronas de la capa ya que como se ha descrito en la sección puede que una neurona como entradas las salidas de varias funciones de activación las neuronas tipo pnorm por ejemplo cada una de las funciones de las funciones de propagación propagación se tal y como aparece en la ecuación bloqueprop donde es la dimensión del vector de salida de la capa es la salida de la neurona de la capa es el peso que relaciona la salida de la neurona de la capa con la función de propagación y el bias asociado a la función de propagación una vez las salidas del bloque de funciones de propagación cada una de las salidas de la capa se puede computar haciendo uso de por ejemplo las funciones de activación en la ecuación bloqueact donde es la salida de la neurona de la capa y el vector de entrada a la función de activación en el caso de que la función de activación tenga una sola entrada podemos la ecuación bloqueact como se muestra en la ecuación ecuación donde las ecuaciones bloqueprop y bloqueact muestran como calcular la salida de una capa de una red feedforward en función de la capa anterior por tanto para computar la salida de la red con aplicar las ecuaciones bloqueprop y bloqueact por hasta aún así como hemos al analizar las funciones de activación relu y pnorm en ocasiones es necesario añadir componentes de de normalización a algunas capas en ese caso hay que añadir una ecuación más para computar la salida de éstas la normalización que en este trabajo a las capas relu y pnorm se en la ecuación donde es la salida en la ecuación es la estándar de con esta normalización se consigue que la estándar lo cual a el entrenamiento redes tdnn las redes tdnn del inglés son un tipo de redes neuronales cuya estructura está para sobre secuencias de vectores de entrada las tdnn en su entrada una cantidad de vectores de la secuencia unos o vectores en nuestro caso por ejemplo a diferencia de las redes feedforward hasta ahora en las tdnn las capas no están entre ellas grupos de vectores de entrada correspondientes a instantes distintos se procesan en paralelo de forma a lo largo de la red este es equivalente a que la salida de una capa depende de la salida de la capa anterior en distintos instantes de tiempo para esto supongamos que tenemos una red neuronal a feedforward muy simple formada por una capa de entrada la cual no realiza cálculos y una de salida de la red a tenemos una red b formada también por una capa de entrada y una capa de salida supongamos ahora que a la red b un vector o conjunto de vectores centrados en el instante así b el vector de salida de la red b correspondiente a ese instante podemos a la red b un vector o conjunto de vectores centrados en el instante para obtener b si ahora los vectores b y b a la entrada de la red a la red formada por la red a y por la red b en los dos instantes llamaremos a esta red resultante a + + es una tdnn la otra interpretación equivalente de la tdnn a + + se a continuación la tdnn resultante es una red feedforward cuya capa de entrada es la de las capas de entrada de la red b en los instantes y es decir si por ejemplo la red como entrada los vectores y ; y la red y ; la red a + + como entrada los vectores y la red a + + una única capa intermedia en dos cada una de ellas igual a la capa de salida de la red b la primera como entrada y ; y la segunda y por tanto las capas de las redes tdnn no son finalmente la capa de salida de la tdnn a + + es igual a la capa de salida de la red a la capa de salida está con la capa en la figura se muestra este ejemplo de forma gráfica ejemplo de la red tdnn simple las tdnn que utilizaremos en este trabajo son más pero su funcionamiento es similar al del ejemplo anterior al igual que a la red a la salida de la red b en instantes de tiempo la red b puede como entrada la salida de una red en distintos instantes en la figura se muestran dos ejemplos de tdnn más dos ejemplos más de tdnn en cada capa cada las que la capa fuente: con esta estructura se la red la estructura temporal de los acústicos y que las características que cada capa sean independientes del instante en el que éstas ya que las entradas correspondientes a distintos instantes se procesan de forma redes recurrentes en las salidas de algunas capas se de forma que la salidas de una capa depende de sus salidas anteriores las redes que este tipo de capas se redes neuronales recurrentes rnn por sus siglas en inglés la relación entre las salidas de una capa se con las salidas en el instante anterior mediante una extensión del bloque de funciones de propagación tal y como se muestra en la figura representación gráfica de una red neuronal recurrente debido a su estructura las rnn son se están analizando secuencias de vectores de entrada para como computar la salida en este tipo de redes supongamos que que queremos computar las salidas de la red para una secuencia de de vectores de entrada supongamos también que la red está por capas entre las cuales puede haber capas recurrentes y no recurrentes igual que en el caso de las redes feedforward para calcular la salida de la red hemos de las salidas de cada una de las capas por las iniciales si la capa es una capa recurrente de la red su salida para el instante se calcula de la siguiente forma calcular la salida de la función de propagación correspondiente a cada neurona ecuación por que a cada neurona le una única función de propagación el caso más general es muy similar donde es el peso correspondiente a la salida de la neurona de la capa en el instante y la cantidad de neuronas de la capa calcular la salida de cada neurona en función de las salidas de las funciones de propagación ecuación para realizar los dos anteriores se ha que conocemos las salidas de la capa en el instante para calcular este vector se las ecuaciones y desde con unas condiciones iniciales hasta por tanto para calcular la salida en el instante necesitamos también conocer las entradas a la red correspondientes a los instantes redes recurrentes bidireccionales una extensión de las redes recurrentes son las redes recurrentes bidireccionales en el caso anterior hemos descrito como las redes neuronales que contienen capas en las que su salida depende de su salida en el instante lo que que depende de todos los instantes anteriores una versión equivalente las redes recurrentes que contienen capas cuya salida depende de los instantes siguientes es decir de y de las redes recurrentes bidireccionales contienen capas en ambos por tanto para computar la salida de este tipo de redes en el instante necesitamos conocer las entradas a la red correspondientes a todos los instantes de la secuencia redes lstm las redes lstm del inglés son un tipo de rnn cuyo rendimiento se ha ser en una gran de entre las cuales se el reconocimiento de voz una capa de una red lstm está formada por celdas de memoria estas celdas de forma similar a las rnn hasta ahora con el de que no solo se su salida sino también el estado de la celda en la figura se muestra un esquema de una celda lstm este esquema es el mismo utilizado por en esquema de una sola celda lstm la la función en la figura se muestra el esquema de funcionamiento de una celda lstm como se la salida depende de la entrada a la celda la memoria de la celda en el instante anterior de la salida de la celda en el instante anterior en la celda además podemos encontrar diferentes con diferentes la memoria de la celda indica cómo de fácil es que se la celda teniendo en cuenta el estado de la celda lstm en los anteriores estados el valor de la gate se a la memoria de la celda así la gate acotada entre 0 y 1 cuanto de la memoria tenemos que o la gate se de la cantidad que tenemos que añadir o a la memoria finalmente la gate al igual que la memoria en el valor final de la salida de la celda la salida de la celda ecuación se en función de los valores ecuación ecuación ecuación y ecuación donde cada es el peso correspondiente a la variable y a la celda hay que que todas las variables valores de celda que en las ecuaciones y son hasta ahora se ha descrito el funcionamiento de una celda lstm una capa lstm está formada por varias unas en los experimentos de este trabajo de estas celdas para crear una capa lstm tan solo nos añadir tantas funciones de propagación como celdas a haber en la capa mediante cada función de propagación las entradas a las celdas lstm la que aparece en las ecuaciones anteriores de la forma ecuación bloqueprop al igual que con todas las rnn se puede implementar una red lstm con distintas capas lstm si en algunas se tiene en cuenta el y en las otras el entrenamiento de las redes neuronales al igual que en los hmm para que las redes neuronales sean en la práctica es necesario un algoritmo o conjunto de algoritmos que ajustar los parámetros de estas redes en general los pesos y bias a partir de unos datos o ejemplos de entrenamiento en este caso los ejemplos de entrenamiento en un conjunto de ; donde cada una de las entradas a la red la salida para la entrada y es un índice que varía entre y siendo la cantidad de ejemplos de entrenamiento función objetivo o de coste el primer paso para entrenar redes neuronales es definir una función que como de bien se sus parámetros al conjunto de los ejemplos de entrenamiento esta función se conoce como función de coste o función objetivo una propiedad de las funciones de coste es que se haciendo la media entre los costes correspondientes a cada ejemplo de entrenamiento ecuación costes donde representa el conjunto de todos los pesos de la red neuronal todos los bias y es el coste correspondiente al ejemplo de entrenamiento para como estos costes la función de coste cuadrático ecuación donde es el vector de salida de la red para el vector de entrada que aunque no se muestra en la ecuación por por depende de y si analizamos la función de coste cuadrático que además cuanto mayor sea la diferencia entre los vectores de salida y los vectores de salida de la red mayor será el coste cuadrático si por el las salidas de la redes se a los vectores el coste cuadrático así tenemos que ajustar los pesos y los bias para que aunque la función de coste es para ajustar los pesos y bias existen otras funciones más para el entrenamiento de redes neuronales en este trabajo se la función de coste cross-entropy ecuación la cual permite un entrenamiento más que la función de coste cuadrático donde y son cada uno de los componentes de cada uno de los vectores de salida y obtenidos a partir de la entrada respectivamente al igual que la función de coste cuadrático la función de coste cross-entropy es siempre mayor o igual a y más pequeña cuanto menos las salidas y las en cualquier caso nuestro objetivo es minimizar la función de coste que una sería calcular el mínimo de esa función pero las redes neuronales suelen y de forma de al menos de variables así que calcular todas las derivadas parciales a y resolver el sistema no es por tanto se suele resolver el problema de la de forma mediante el algoritmo de descenso de gradiente descenso de gradiente el descenso de gradiente permite calcular un mínimo local de una función de varias variables es un algoritmo cuyo funcionamiento se a comenzar el valor del gradiente de la función para un punto por ejemplo si la función a minimizar es el gradiente en el punto se calcula de acuerdo a la ecuación calcular el siguiente punto en el punto anterior en la primera iteración y el gradiente correspondiente ecuación donde es una constante conocida como de aprendizaje o rate es fácil que el valor de la función en el punto que con esta de variables es menor al anterior siempre que la constante sea suficientemente pequeña se puede que el cambio en el valor de la función dado por la expresión mostrada en la ecuación una vez las variables podemos a calcular el gradiente de la función ecuación o si que ya hemos suficiente el valor de la función de coste podemos el algoritmo con los últimos valores de las variables cada una de las es conocida como época de entrenamiento en el caso del entrenamiento de las redes neuronales las ecuaciones de de variables cómo hemos de los pesos y bias para conseguir que las salidas de la red sean las ecuaciones y aunque el algoritmo de descenso de gradiente y permite ajustar los parámetros de las redes neuronales dos problemas el primero es que tan solo nos permite encontrar un mínimo local de la función de coste siempre que un número de épocas y un valor de de aprendizaje figura gráfica del algoritmo de descenso de gradiente sobre una función de dos variables se muestran tres ejemplos desde tres puntos los que no se el mínimo de la función el otro es que es necesario computar el gradiente de la función de coste como se puede observar en la ecuación costes la funciones de coste de componentes una por ejemplo de entrenamiento por tanto a la del gradiente podemos computar el gradiente de la función de coste haciendo la media entre los gradiente correspondientes a cada ejemplo de entrenamiento si el de datos de entrenamiento es muy grande y en el caso de reconocimiento de voz suele el tiempo entre las de variables es demasiado grande debido a estos dos se suele por una versión del algoritmo de descenso de gradiente conocido descenso de gradiente estocástico para entrenar redes neuronales descenso de gradiente estocástico el algoritmo de descenso de gradiente estocástico se en dividir cada época en como y los parámetros de la red neuronal con cada uno de el funcionamiento de esta del descenso de gradiente se a continuación dividir los ejemplos de entrenamiento en de tamaño el valor de suele entre y por cada estimar el gradiente de la función de coste para ello se la aproximación de la función de coste que se muestra en la ecuación donde es cada uno de los componentes de la función de coste correspondientes al con esta aproximación y teniendo en cuenta la del gradiente las ecuaciones de de los pesos y bias son las en las ecuaciones y al igual que en el algoritmo de descenso de gradiente en este punto podemos a entrenar la red una época más o con los últimos pesos y bias una vez el funcionamiento del algoritmo podemos una de por qué el descenso de gradiente estocástico los problemas del descenso de gradiente por una parte al las variables más a se el además el hecho de computar una aproximación del gradiente que el algoritmo no a hacia el mismo mínimo local todo el figura de forma que es más probable en un mínimo local de menor valor o en el mínimo de la función en la función de coste en función de las distintas de variables fuente: para la sección del entrenamiento de las redes neuronales es necesario describir el algoritmo de o propagación hacia atrás éste una forma para computar las derivadas parciales que en las ecuaciones y propagación hacia atrás el algoritmo de propagación hacia atrás en la década de los pero hasta no se su uso en ese y que mediante la propagación hacia atrás se pueden entrenar de forma redes neuronales de varias capas para calcular las derivadas parciales correspondientes a cada uno de los ejemplos de entrenamiento se la función de error correspondiente a una neurona de la red ecuación que representa varía la función de coste correspondiente a un ejemplo de entrenamiento al la entrada a la función de activación de una neurona de la red por se analizará el caso en el que a cada neurona le corresponde una sola función de activación donde es el error correspondiente a la neurona de la capa de la red neuronal es la entrada a la función de activación correspondiente a la neurona de la capa de la red neuronal y es el coste correspondiente al ejemplo de entrenamiento se ha que es una función de y por por tanto con la expresión mostrada en la ecuación podemos conocer los errores correspondientes a todas las neuronas de la el índice varía entre y la cantidad de capas de la red y entre y la dimensión cantidad de neuronas de la capa una vez la función de error es conveniente en de la salida de la neurona y de la función de activación ecuación el procedimiento para calcular la derivada del coste de un ejemplo de entrenamiento respecto a un peso o bias dado se a continuación el algoritmo de propagación hacia atrás se en hacia las neuronas de las capas iniciales el error de las capas más a la salida de la red el primer paso es por tanto calcular los errores en la capa de salida capa con índice ecuación la ecuación muestra el error de una de neurona de la capa de salida para como el algoritmo es más conveniente utilizar la expresión mostrada en la ecuación que muestra el error de todas las neuronas de la última capa donde contiene las derivadas parciales del la función de coste respecto a la salida de todas las neuronas de la última capa es un vector componentes son y representa el de elemento a elemento estos errores se pueden calcular por un lado conocemos cómo depende la función de coste correspondiente al ejemplo de entrenamiento de la salida de la red neuronal por ejemplo en el caso de la función de coste cuadrático donde es conocido la salida y se puede calcular a partir de los parámetros de la red y de la entrada por el otro lado como conocemos la función de activación conocemos también su derivada por tanto podemos computar los componentes del vector cada componente de a partir de los parámetros de la red y de la entrada propagación hacia atrás del error una vez se ha el error en la capa de salida se puede calcular el error de cualquier neurona de cualquier otra capa hacia atrás los errores capa a capa la ecuación muestra cómo calcular el vector de errores de la capa en función de los errores de la capa donde es la matriz de pesos correspondiente a la capa la de que se muestra a en las ecuaciones bp22 y en las que se han utilizado que se a cada neurona de cada capa no donde es la entrada a cada una de las funciones de activación de la capa en la ecuación se ha la de la cadena a la de teniendo en cuenta que cada depende de para calcular la derivada hemos de en de ecuación bp22 donde es el peso que relaciona la salida de la neurona de la capa con la neurona de la capa y el bias correspondiente a la neurona de la capa en la ecuación bp22 se ha que la función de propagación de las neuronas de la capa es la mostrada en la ecuación la ecuación bp22 la expresión de el resultado de de la ecuación en la ecuación una expresión elemento a elemento equivalente a la ecuación la cual está en forma derivada de la función de coste respecto a cualquier bias de la red como y calcular las derivadas de la función de coste respecto a cualquier bias es una vez que hemos los errores ecuación simplemente hemos de aplicar la de derivada de la función de coste respecto a cualquier peso de la red igual que con los bias con aplicar la de para conseguir la derivada de la función de coste respecto a cualquier peso ecuación donde es el peso que relaciona la salida de la neurona de la capa con la neurona de la capa propagación hacia atrás a lo largo del tiempo el algoritmo de propagación hacia atrás permite calcular cómo los pesos y bias de una red neuronal feedforward en la función de coste en el caso de las redes neuronales recurrentes rnn es una extensión de este algoritmo la cual se conoce como propagación hacia atrás a lo largo del tiempo o por sus siglas en inglés esta extensión en realizar un paso antes de aplicar el algoritmo de propagación hacia atrás estándar este paso se la rnn al una rnn para un instante de tiempo se una red neuronal feedforward equivalente para ese instante de tiempo en la figura se muestra un ejemplo la estructura de una red neuronal feedforward equivalente a una rnn tal y como se en la sección para calcular la salida de la red en el instante es necesario en este ejemplo las salidas de la capa intermedia recurrente en el instante para conocer las salidas de la capa intermedia recurrente en el instante necesitamos conocer las entradas a la red en el instante y las salidas de la capa intermedia en el instante y así hasta llegar al instante en el que la secuencia de entradas a la red rnn equivalente feedforward para el instante de una rnn con una capa recurrente y una capa de salida no recurrente y de su equivalente feedforward y son las de pesos y bias de la rnn relaciona la capa intermedia con la de las entradas con la capa y las salidas de la capa intermedia en el instante anterior con la capa intermedia en el instante actual fuente: por tanto si estamos la rnn mediante una secuencia de ejemplos de la rnn veces para conseguir feedforward para cada uno de esos instantes para los primeros ejemplos de entrenamiento la red equivalente no será demasiado grande pero nos vamos al final de la secuencia las redes contienen capas para el entrenamiento se suelen el número de instantes hacia atrás con los que las redes en cualquier caso una vez que de las redes neuronales feedforward podemos aplicar el algoritmo de propagación hacia atrás estándar para calcular las derivadas en el algoritmo de descenso de gradiente estocástico con la de que hay que tener en cuenta que los pesos y bias en estas redes feedforward son tenemos los pesos y bias en distintos instantes de tiempo sistemas de reconocimiento de voz en el capítulo se el problema del reconocimiento de voz desde un punto de con el objetivo de encontrar la secuencia de palabras más probable teniendo en cuenta una entrada acústica ecuación problema se el problema en modelización acústica y del lenguaje ecuación bayes a lo largo del capítulo se describió también cómo obtener una secuencia de vectores que la señal acústica que queremos analizar sección parametrización cómo una secuencia de palabras en secuencias de fonemas o trifonemas sección y cómo estimar la probabilidad de una secuencia de palabras mediante un modelo de lenguaje sección así la ecuación problema se puede desarrollar hasta llegar a la siguiente expresión ecuación donde representa una secuencia de vectores de parámetros correspondientes a una señal acústica y y son las secuencia de fonemas y trifonemas correspondientes a la secuencia de palabras durante este capítulo analizaremos la estructura entrenamiento y decodificación en los sistemas gmm-hmm y dnn-hmm finalmente introduciremos parametrizaciones a los vectores mfcc para representar la señal acústica modelos ocultos de markov basados en mezclas de gaussianas los hmm son para resolver el problema de modelización acústica ya que observaciones no son directamente las unidades que queremos modelizar sino por ejemplo los vectores de parámetros descritos en la sección parametrización o la que introduciremos en la sección se una de vectores a los parámetros de vectores para poder con hmm que secuencias de símbolos discretos después estos símbolos por mezclas de gaussianas que cada uno de los componentes de los vectores de parámetros en esta sección utilizaremos los hmm y las gmm para las probabilidades y como se ha en la sección hmm los hmm sirven para modelizar sistemas memoria por tanto que las secuencias de vectores de parámetros correspondientes a un fonema o trifonema dado son por un sistema estocástico memoria podemos tantos hmm como unidades fonéticas se representar en el caso del castellano serán unos si tenemos en cuenta el si estamos fonemas y de si trifonemas hmm de fonemas es utilizar hmm con topología de bakis para representar cada fonema el un hmm con esta topología está formado de tres estado y final figura bakis en cada estado existe una probabilidad de al siguiente estado y otra probabilidad de en el mismo estado a cada estado se le una gmm formada por gaussianas para estimar la probabilidad de emisión de vectores de la misma dimensión que los vectores de parámetros utilizados en el caso de la parametrización mfcc la dimensión sería con esta estructura se representar las distintas del la la y el final del fonema aunque es que el sonido correspondiente a fonemas no tiene esa estructura temporal estructura de un hmm con topología de bakis entrenamiento una vez la estructura de todos los hmm describiremos como entrenar éstos nuestro corpus de entrenamiento consta de audios y sus correspondientes transcripciones cada audio contiene en la mayoría de los casos frases de unas palabras por tanto no podemos aplicar directamente el entrenamiento mediante viterbi analizado en la sección ya que la secuencia de vectores de parámetros de cada audio no se va a a un solo fonema es decir tenemos que tener en cuenta que la secuencia de vectores correspondiente a cada audio está formada por correspondientes a cada fonema que ha sido en ese audio así por cada audio se pueden entrenar los hmm de los fonemas de acuerdo a la transcripción de ese audio y al léxico por ejemplo supongamos que tenemos un audio cuya transcripción es de acuerdo a las reglas del castellano el audio los siguientes /a/ en este mismo orden con esta información podemos los hmm correspondientes a esos fonemas tal como se muestra en la figura hmm correspondiente a la frase esta formado por los hmm de cada uno de los fonemas que se al decir esta frase representa el estado del hmm correspondiente al fonema una vez tenemos el hmm de la frase podemos con el mismo procedimiento descrito en la sección al llevar a cabo las en el entrenamiento se ha de tener en cuenta que puede que distintos estados del hmm de la frase sus parámetros porque es posible que en una frase se más de una vez un fonema este procedimiento con todos los audios y transcripciones del corpus de entrenamiento podemos entrenar las probabilidades de transición y los parámetros de las gmm de los estados de los hmm de todos los fonemas decodificación con los hmm de los fonemas entrenados podemos desarrollando el problema del reconocimiento de voz como la secuencia de fonemas se puede obtener a partir de distintas secuencias de estados de los hmm entrenados podemos la ecuación tal y como aparece a continuación ecuación hmmfon donde es el conjunto de todas las posibles secuencias de estados de los hmm de fonemas que en este punto todas las probabilidades de la ecuación hmmfon son en primer lugar la probabilidad de cualquier secuencia de palabras se puede estimar a partir de un modelo de lenguaje después esa misma secuencia puede ser mediante reglas en una única en nuestro caso secuencia de fonemas indica la probabilidad de que la secuencia de fonemas haya sido mediante la secuencia de estados esta probabilidad puede a partir de las probabilidades de transición de los hmm de los fonemas entrenados ecuación donde es la probabilidad de transición del estado al estado finalmente el cálculo de puede a cabo con la información de las probabilidades de emisión de cada uno de los estados de los hmm de los fonemas ecuación donde es la probabilidad de emisión del vector en el estado aunque hemos mostrado como calcular la probabilidad de una secuencia de palabras y una secuencia de estados de hmm existen secuencias de palabras y secuencias de estados de los hmm posibles además aunque por cada secuencia de palabras no todas las secuencias de estados son posibles existe un de secuencias de estados posibles para cada secuencia de palabras debido a los en los hmm de los fonemas por tanto el de calcular la probabilidad de todas las secuencias de palabras no es para calcular la secuencia de palabras más probable en su lugar se realiza una búsqueda de viterbi sobre un hmm a partir del modelo de lenguaje las reglas de pronunciación y los hmm de los fonemas como tenemos un hmm por fonema podemos de acuerdo al léxico para hmms de cada palabra en nuestro de la misma forma una vez que tenemos los hmm de las palabras podemos de acuerdo a un modelo de lenguaje y un hmm que la información de nuestro reconocedor de voz realizando una decodificación mediante por ejemplo el algoritmo de viterbi sobre dicho hmm podríamos calcular la secuencia de palabras más probable dada una señal acústica es decir podríamos encontrar la al problema en la ecuación hmmfon en la sección wfst la práctica de este gran hmm y del algoritmo de viterbi sobre éste hmm de trifonemas en este caso el número de hmms que se será igual al número de trifonemas y su topología será también de bakis para entrenar estos hmm se pueden deducir las secuencias de trifonemas correspondientes a las transcripciones del corpus a partir de la secuencia de fonemas en el anterior tal y como se en la sección aún así existen algunas entre los casos de fonemas y trifonemas la cantidad de trifonemas en una es mayor al de fonemas número de fonemas a tres el número de parámetros a entrenar aumenta en gran medida además existen trifonemas muy que van a ser en o ocasiones en durante el entrenamiento por ejemplo para los problemas que por un entrenamiento de los hmm de trifonemas se estados de hmms de distintos trifonemas no se los hmm de los trifonemas desde se suelen como los modelos de fonemas descritos en el anterior así los parámetros de los hmm de cada trifonema se con los parámetros del hmm del fonema correspondiente por ejemplo los parámetros iniciales del trifonema a serán los parámetros del hmm del fonema /a/ una vez los hmm se estados de los hmm de los trifonemas correspondientes al mismo fonema se pueden utilizar tanto como para llevar estos algoritmos para realizar los están descritos en finalmente podemos entrenar los hmm de los trifonemas igual que en el caso de los los hmm de las frases de transcripción y los parámetros de cada estado mediante un entrenamiento viterbi para estimar la secuencia de palabras más probable correspondiente a una secuencia de vectores acústicos dada podemos desarrollar la ecuación como en el caso de los fonemas la única diferencia es que hemos los fonemas en trifonemas en la ecuación hmmtri se muestra el desarrollo el cálculo de se puede llevar a cabo igual que en el caso de los fonemas modelos híbridos entre modelos ocultos de markov y redes neuronales aunque las mezclas de gaussianas sirven para realizar modelos acústicos de los distintos sonidos al distintos experimentos y que mediante las redes neuronales se pueden conseguir reconocedores de voz de mayor en los modelos híbridos las redes neuronales a las gmm las gmm el cálculo de la probabilidad es decir dada una secuencia de estado de hmm de fonemas o trifonemas la probabilidad de que se haya producido la secuencia de observaciones de vectores acústicos las redes neuronales se para estimar la probabilidad de cada estado de cada hmm de trifonemas solo utilizaremos trifonemas en los modelos híbridos en función de una entrada acústica es decir para ello la entrada a la red será un vector o conjunto de vectores de parámetros y cada una de las neuronas de la capa salida la probabilidad de cada uno de los estados de los hmm de trifonemas como la probabilidad no aparece en la ecuación hmmtri es necesario esta expresión para que tenga en el contexto de modelos híbridos entre hmm y redes neuronales podemos aplicar el de bayes a la probabilidad tal y como se muestra a continuación ecuación dnntri en la ecuación dnntri podemos el ya que solo a los valores de las probabilidades no a la secuencia óptima de palabras como hemos dicho podemos calcular la probabilidad a partir de las salidas de la red neuronal ecuación probdnn donde es la salida de la neurona de la capa de salida correspondiente al estado y al instante es conveniente mencionar que en la ecuación probdnn se muestra que la salida de la red en el instante no depende solo del vector acústico correspondiente a ese instante en su lugar la salida depende de un conjunto de vectores acústicos centrados en es decir la red neuronal las probabilidades de los estados del hmm en el vector acústico correspondiente al instante y también en los vectores acústicos anteriores y a ese instante esto es conocido como la probabilidad de la ecuación dnntri se puede obtener a partir de las probabilidades a de cada estado ecuación las cuales se calculan a partir de las durante el entrenamiento de los hmm de los trifonemas donde es la cantidad de ocasiones que el estado aparece en las mediante el entrenamiento de viterbi de los hmm de trifonemas y la cantidad total de vectores acústicos en el entrenamiento entrenamiento de las redes neuronales en el contexto de reconocimiento de voz en la sección trainnn analizamos como entrenar redes neuronales mediante ejemplos de entrenamiento por donde es cada una de las entradas a la red del corpus de entrenamiento y la salida para la entrada nuestro corpus de entrenamiento está formado por un conjunto de audios y sus correspondientes transcripciones por tanto no podemos entrenar las redes neuronales directamente con este corpus ya que la entrada a una red no serán todos los vectores acústicos del audio de una frase sino el vector correspondiente a un instante dado más unos vectores anteriores y para que la red tenga información del contexto además las salidas de la red son las probabilidades de cada estado de los hmm de trifonemas no palabras en es necesario un de los vectores acústicos que los audios para poder entrenar las redes neuronales esta se suelen conseguir mediante el entrenamiento de viterbi de un sistema gmm-hmm basado en trifonemas así el entrenamiento de las redes neuronales se de forma posterior al entrenamiento del sistema gmm-hmm basado en trifonemas el cual se ha entrenado a partir de un sistema gmm-hmm basado en fonemas una vez que tenemos los audios de entrenamiento podemos entrenar las redes neuronales tal y como se describió en la sección trainnn cada ejemplo de entrenamiento de un conjunto de vectores acústicos centrados en el instante y del vector de salida el cual se calcula el del todos los componentes de serán el correspondiente al estado que será con estado nos al estado de los hmms que corresponde al instante la alineación mediante el entrenamiento de viterbi el hecho de tener el corpus de entrenamiento en frases nos permite por otro lado definir funciones de coste más que las funciones de coste cuadrático y cross-entropy ecuaciones y respectivamente en este trabajo con la función mmi la cual se en el mmi del inglés la función de coste mmi se muestra en la ecuación mmi donde es el número de frases del corpus la secuencia de vectores acústicos del ejemplo de entrenamiento su alineación en estados de los hmm de trifonemas su transcripción y el conjunto de todas las posibles secuencias de palabras las probabilidades y de la ecuación mmi se pueden calcular aplicando el de bayes ecuaciones probdnn y las probabilidades y calculan mediante un modelo de lenguaje sección en la suma que se muestra en el ha de ser sobre todas las posibles secuencias de palabras y todas las posibles en cada secuencia aunque esta suma no se muestra esa suma no es en su lugar se realiza sobre unas secuencias de palabras que se aplicando el algoritmo al ejemplo de entrenamiento el algoritmo es una del algoritmo de viterbi mientras que el algoritmo de viterbi la secuencia de estados con mayor probabilidad teniendo en cuenta una secuencia de observaciones y su probabilidad el algoritmo consigue las secuencias y sus probabilidades parametrizaciones de los vectores acústicos en la sección parametrización se los vectores por los coeficientes mfcc se la razón del uso de este tipo de vectores en la tarea de reconocimiento de voz así como el procedimiento para la de los coeficientes mfcc a partir de una señal acústica a continuación introduciremos y de los coeficientes mfcc normalización de la media y varianza la normalización de la media y varianza por sus siglas en inglés es una normalización que permite aumentar la ante el de los vectores mfcc la normalización cada componente de los vectores mfcc para que cada uno de estos presente media y varianza por frase o por hablante ecuación donde es el componente del vector acústico correspondiente al instante y su versión y son la media y la varianza del componente sobre todos los componentes correspondientes a la frase o hablante ecuaciones y donde es cada uno de los vectores correspondientes a la misma frase o hablante coeficientes + ya que el de es puede ser computar parámetros que la de los coeficientes mfcc a lo largo del tiempo se como coeficientes delta los a la diferencia de valor de los mfcc entre ventana y ventana coeficientes de y como delta delta los al cambio de los coeficientes delta entre ventana y ventana coeficientes de se tantos coeficientes delta y como mfcc y éstos serán al vector mfcc por tanto si nuestro vectores mfcc son de dimensión los vectores mfcc + serán de dimensión y los mfcc + + de dimensión en las ecuaciones delta y se muestra cómo calcular los coeficientes y respectivamente donde es el componente del vector correspondiente al instante es el componente del vector mfcc correspondiente al instante y el número de ventanas hacia y atrás que utilizamos para calcular estos coeficientes en nuestro caso será igual a 2 los coeficientes se calculan igual que los pero a partir de los coeficientes en vez de los mfcc donde es el componente del vector correspondiente al instante transformación lda en el ámbito de reconocimiento de voz la transformación lda del inglés linear es utilizada como una de de vectores acústicos una transformación lda un vector de entrada a un de menor dimensión donde la entre las clases de los vectores sea mejor una ejemplo y simple se muestra en la figura ejemplo de dos posibles de un conjunto de vectores en dos clases ambas la dimensión de cada vector de dos a uno una de las la permite los vectores mientras que la otra la que la sea más fuente: por tanto solo podemos aplicar esta transformación a vectores en nuestro caso en estados de trifonemas esta se suele hacer mediante un sistema gmm-hmm además como la transformación reduce la dimensión se suele aplicar a una pequeña secuencia de vectores para que el vector resultante información del contexto por ejemplo si queremos obtener el vector lda correspondiente a un vector mfcc podemos vectores mfcc los cuatro el central y los cuatro es que el vector lda resultante tenga dimensión 40 los detalles de la transformación lda se en transformación mllt el objetivo de la transformación mllt del inglés linear es el mismo que el de la transformación un vector la mllt un vector para que sus parámetros ser más mediante gaussianas con una matriz de la transformación mllt no reduce la dimensión de los vectores a los que se en la práctica la mllt a vectores lda los detalles de la transformación mllt se en transformación fmllr la transformación fmllr del inglés linear es una transformación que la dimensión de los vectores y permite vectores acústicos al hablante la general de esta transformación es como todos de forma distinta unos vectores en los que las de los distintos sean lo menos posible para ello la fmllr la media y varianza de los vectores correspondientes a un mismo hablante y así la general de los vectores de todos los los detalles de la transformación fmllr se en kaldi todos los experimentos a cabo en este trabajo han sido mediante la herramienta kaldi kaldi es una herramienta de uso libre a la en el ámbito del reconocimiento de voz permite el desarrollo de reconocedores de voz basados tanto en los sistemas gmm-hmm como en los modelos híbridos dnn-hmm kaldi está por un conjunto de librerías en por los de esta herramienta y por otras dos librerías y en las librerías de kaldi se todos los algoritmos y clases correspondientes a los hmm gmm dnn parametrización de la señal acústica y también parte de los algoritmos correspondientes a los de estados finitos con pesos wfst por sus siglas en inglés los cuales introduciremos en la sección wfst kaldi utiliza la para realizar cálculos relacionados con la lineal y la para implementar los wfst el a las por estas librerías se mediante en los cuales son mediante de o en general es importante que kaldi el uso de o gpus por sus siglas en inglés en algunas de sus las gpus están por de que son capaces de del tipo es decir pueden realizar una gran cantidad de cálculos en paralelo siempre que la sea la misma tal y como se en el entrenamiento de las redes neuronales puede a cabo mediante en paralelo los cuales se pueden realizar en las gpus así se puede una de las de las redes la en el entrenamiento a continuación se los wfst y se describirán algunas características de las redes neuronales de la herramienta kaldi de estados finitos con pesos en el capítulo reconocedores la ecuación bayes hasta llegar a varias en las que en todos los son ecuación hmmfon para el caso de los sistemas gmm-hmm basados en fonemas ecuación hmmtri para el caso de los sistemas gmm-hmm basados en trifonemas y ecuación dnntri para el caso de los sistemas híbridos dnn-hmm en ese capítulo también se la de realizar una búsqueda de viterbi sobre un hmm que todas las probabilidades de tres ecuaciones a continuación describiremos cómo implementar ese hmm y cómo realizar la búsqueda sobre kaldi este hmm mediante un tipo de conocido como wfst un wfst es una de estados finitos con una de entrada y una de salida un wfst para una secuencia de símbolos del alfabeto de entrada en una o varias secuencia de símbolos del alfabeto de salida además un peso a la secuencia de salida en nuestro caso utilizaremos wfsts y un wfst es si una secuencia de entrada en una sola secuencia de salida además si es estocástico la suma de los pesos correspondientes a las desde un mismo estado para el de los wfst en el contexto de reconocimiento de voz en la figura wfst-fig se muestran tres ejemplos muy de wfsts un modelo de lenguaje unas reglas de pronunciación y el hmm de un fonema respectivamente tres ejemplos de wfst la notación utilizada es la siguiente: entrada salida peso fuente: analizando el de la figura wfst-fig este wfst representa un modelo de lenguaje el alfabeto de entrada de es el conjunto de palabras que forma un aunque no se en el la salida de es la misma secuencia de entrada más el peso correspondiente a ésta con una estructura se puede representar cualquier modelo de lenguaje basado en con este wfst en modelo de lenguaje de nuestro ejemplo nos permite conocer la probabilidad por ejemplo del si esta cadena a la salida si los peso como probabilidades la probabilidad de dicho es ahora el wfst del léxico secuencias de fonemas a secuencias de palabras en el caso del castellano y en el del ejemplo de la figura wfst-fig también el wfst es simplemente un como solo una pronunciación por palabra cualquier cadena de salida probabilidad y por tanto no es necesario el peso por ejemplo ante la entrada la salida de para con el léxico la mencionar que en este wfst no tiene por qué la de ser debido a las palabras una misma de secuencia de fonemas puede a más de una palabra este problema se mediante la de símbolos de el último wfst mostrado en la figura wfst-fig es el wfst el cual contiene la información de la estructura y de las probabilidades de transición del hmm de un fonema secuencias de estados de hmms en secuencias de fonemas y además también la probabilidad el peso de que esa secuencia de estados haya producido la secuencia de fonemas por ejemplo ante la entrada donde es la probabilidad de transición del estado del hmm al estado con estos tres wfsts y con las probabilidades de emisión de los estados de los hmm de fonemas tenemos suficiente para representar un sistema gmm-hmm que fonemas para el de trifonemas se un wfst que secuencias de trifonemas en secuencias de fonemas que ya analizamos cómo hacer a en la sección un ejemplo se muestra en la figura ejemplo de un wfst la notación utilizada para la entrada los trifonemas fonema anterior fonema central + fonema posterior fuente: al igual que en el caso del castellano no peso ya que a una secuencia de trifonemas le corresponde una única o si la secuencia de trifonemas no es secuencia de fonemas por ejemplo ante la secuencia de entrada /a/ /a/ con los cuatro wfsts y podemos representar un sistema gmm-hmm o dnn-hmm basado en trifonemas aún así hemos de estos wfst para lograr una de secuencias de estados de hmm de trifonemas a palabras la es una de las de los wfst al dos wfsts se un wfst cuyo alfabeto de entrada es el mismo al del primer wfst y cuyo alfabeto de salida es el mismo al del segundo wfst además ante una secuencia de entrada la salida de es la igual a la salida si a la entrada se la salida de ante esta propiedad es similar a la de funciones por tanto si los cuatro wfsts descritos un wfst que de estados de los hmm a palabras el cual como ecuación en el caso de sistemas basados en fonemas solo que y una vez que tenemos el wfst podemos como estimar la secuencia de palabras más probable para una secuencia de vectores acústicos dada para una secuencia de estados de hmm de trifonemas dada nos la secuencia de palabras correspondiente y su probabilidad mediante o del reconocedor que utilizando podemos calcular la probabilidad que cada componente de la secuencia de vectores acústicos haya sido por cada estado de los hmm de trifonemas ecuación o probdnn con estas probabilidades podemos realizar una búsqueda de viterbi en el wfst en el contexto de wfst para realizar esta búsqueda se un wfst que contiene todas las probabilidades por las gmm o dnn figura después se a para forma el grafo de búsqueda sobre el cual se realiza finalmente la decodificación mediante el algoritmo de viterbi ejemplo de un wfst para un hmm con estados y a la de realizar la decodificación hay que tener en cuenta que el grafo es un grafo muy grande suficientemente grande como para que el algoritmo de viterbi tal y como se describió en la sección decviterbi no sea en cada iteración de dicho algoritmo por cada estado del hmm se como estado anterior que la probabilidad teniendo en cuenta la probabilidad de haber estado en ese estado en el instante anterior y haber al estado actual por tanto en cada iteración se han de realizar del orden de cálculos si es el número de estados del hmm el grafo contiene todos los hmms de todos los trifonemas por lo que suele de al menos de para tener que hacer tantos cálculos en cada iteración no se todos los posibles anteriores solo los que mayor probabilidad por ejemplo los estados con mayor probabilidad esta versión del algoritmo de viterbi es conocida como redes neuronales en kaldi a día de kaldi tres de distintos para el desarrollo de redes nnet2 y nnet3 en este trabajo se con redes correspondientes a los nnet2 y nnet3 las características entre nnet2 y nnet3 más son las [• ] no se utiliza tipo de de las redes neuronales los parámetros iniciales se de forma [• ] de forma al primer bloque de funciones de transferencia de la primera capa de las redes se una transformación lineal al conjunto de vectores de entrada esta transformación es sus parámetros no se durante el entrenamiento y aunque es similar a una transformación del tipo lda no reduce la dimensión de los vectores de entrada el objetivo de esta transformación es los vectores de entrada para la entre clases de éstos y aumentar así el rendimiento de la red [• ] la constante de de aprendizaje o rate a lo largo de las épocas para la del descenso de gradiente estocástico este es [• ] también con el objetivo de la del descenso estocástico de gradiente se el cambio de los pesos y bias de la red por [• ] para obtener el modelo final de una red un entrenamiento no se como modelo final el modelo correspondiente a la última época en su lugar se una media de los últimos modelos de los últimos por ejemplo los pesos se la función de coste en un de del conjunto de datos de entrenamiento existen dos entre nnet2 y nnet3 la primera es los de redes que pueden ser el paquete nnet2 está para utilizar redes feedforward como por ejemplo redes en funciones de activación como la tangente hiperbólica la o la función pnorm en el paquete nnet3 se pueden implementar además de las redes correspondientes a nnet2 redes neuronales con estructuras más como redes tdnn o lstm en segundo lugar el entrenamiento de las redes neuronales es en los casos de nnet2 y nnet3 en nnet2 las redes se mediante la función de coste cross-entropy tal y como se describió en la sección trainnn en nnet3 el entrenamiento se por secuencias mediante la función de coste mmi como analizamos en la sección en este capítulo se distintos experimentos para analizar los diferentes sistemas de reconocimiento de voz descritos durante este trabajo como un reconocedor de voz después describiremos los corpus utilizados para llevar a cabo los experimentos con los cuales el capítulo del rendimiento de un reconocedor de voz supongamos que hemos un sistema reconocedor de voz y queremos su rendimiento si nuestro sistema se de un reconocedor de palabras aisladas su salida sería una sola palabra en cualquier caso podríamos su rendimiento haciendo uso de una medida wer del inglés error rate para calcular el wer se al reconocedor una cantidad de señales en las que se ha una palabra conocida por audio después se cada una de las salidas del reconocedor para conseguir el de palabras ecuación donde es el número de palabras correctas esta medida es para reconocedores de palabras aisladas pero no para los reconocedores desarrollados en este trabajo en nuestro caso todos los sistemas desarrollados tienen como salida la secuencia de palabras que que es más probable teniendo en cuenta una señal acústica una extensión del wer sería la medida ser del inglés error rate como en este caso vamos a al reconocedor señales correspondientes a frases el valor del ser es el de frases correctas aún así en este trabajo no utilizaremos el ser ya que en casos puede no ser del rendimiento de un reconocedor de voz por ejemplo supongamos que tenemos un reconocedor que de media una palabra por cada dos y que las frases que le al reconocedor en el test tienen unas palabras el ser en ese caso sería muy el aunque estamos la de palabras el problema es que la medida ser es de la de las frases cuanto más mayor será el ser de la de palabras en utilizaremos otra extensión del wer para el reconocimiento de palabras aisladas que la de palabras a la que también llamaremos wer el wer para el reconocimiento de habla continua se como se muestra a continuación ecuación donde es el número total de palabras en las transcripciones del test el número de para la salida del reconocedor en la transcripción el número palabras que han de ser para conseguir la transcripción a partir de la salida del reconocedor y el número palabras que han de ser el wer es una medida del rendimiento de los reconocedores de voz más a la que el ser buena muestra de ello es que el wer es utilizado en la mayoría de de y relacionados con el reconocimiento de voz de los corpus utilizados para desarrollar un reconocedor de voz son corpus para el desarrollo tanto para modelos acústicos como para modelos de lenguaje en este trabajo se han utilizado los corpus en la tabla para el desarrollo modelos acústicos corpus utilizados para el entrenamiento y test de modelos acústicos albayzin está formado por a frases es habla el corpus uam lo de y los audios son de todos los audios están a para desarrollar modelos acústicos es necesario un corpus de entrenamiento pero también de test para poder y analizar los modelos y poder en este trabajo se ha cada uno de los corpus en entrenamiento 80 aproximadamente y test 20 restante es muy importante dividir el corpus en entrenamiento y test en vez de utilizar como test un del entrenamiento en dicho caso no podríamos la capacidad para generalizar de los modelos solo si son capaces de los datos de entrenamiento para construir los modelos de lenguaje en el test se por una parte las transcripciones de los audios de los corpus en la tabla por otra parte también se experimentos con un corpus del el país un de los corpus utilizados para modelos de lenguaje se muestra en la tabla corpus utilizados para el entrenamiento de modelos de lenguaje para construir los modelos de lenguaje a partir de los corpus de audios no se han utilizado todas las transcripciones solo las de entrenamiento el 80 si se las transcripciones correspondientes al test los resultados no sido ya que el modelo de lenguaje una probabilidad muy a las secuencias de palabras que se van a intentar reconocer y se las transcripciones correctas si los modelos acústicos no han funcionado del todo bien de los modelos acústicos entrenados ahora a describir las especificaciones de los distintos modelos acústicos a lo largo del trabajo para su rendimiento y gmm-hmm basado en fonemas desarrollando un sistema gmm-hmm basado en fonemas se un hmm con topología de bakis sección por fonema la probabilidad de emisión en cada estado del sistema será mediante una mezcla de gaussianas para desarrollar este sistema se un entrenamiento de viterbi tal y como se describió en las y en las que las observaciones serán vectores + sección estos vectores se a los vectores mfcc a partir de las señales los cuales se mediante una por hablante podemos realizar la normalización por hablante porque conocemos el hablante de todas las frases al entrenamiento de modelos acústicos gmm-hmm basado en trifonemas parametrización + una vez tenemos el sistema gmm-hmm basado en fonemas podemos un sistema gmm-hmm basado en trifonemas en la alineación de los audios a de estado de hmm de entrenamiento con el sistema de fonemas tal y como se en la sección hmmtri la parametrización de la acústica es la misma que en el caso anterior vectores + parametrización lda + mllt podemos desarrollando el sistema de trifonemas aplicando las transformaciones lda primero y mllt después a los vectores mfcc los cuales han sido para computar los vectores + de los casos anteriores como estas transformaciones conocer las clases de los vectores a los que se van a aplicar nos en una alineación con el anterior sistema de trifonemas para conseguir cada vector lda + mllt se la transformación lda a grupos de vectores mfcc estos grupos por un vector mfcc central y cuatro vectores hacia cada lado en total la dimensión de entrada a la transformación será el resultado será un vector lda de dimensión 40 al que se le una transformación mllt para lograr el vector lda + mllt también de dimensión 40 parametrización fmllr el último sistema gmm-hmm que se basado también en trifonemas y los vectores acústicos que se serán los vectores lda + mllt pero con adaptación al hablante para ello se la transformación fmllr los vectores serán de la misma dimensión que los vectores de entrada 40 redes neuronales los ejemplos de entrenamiento de las redes neuronales se los audios de entrenamiento con el último sistema gmm-hmm redes neuronales correspondientes a los de kaldi nnet2 y nnet3 redes en el entorno nnet2 se redes neuronales en las funciones de activación tangente hiperbólica y pnorm los detalles de la estructura y entrenamiento de estas dos redes se en la tabla especificaciones de las redes nnet2 con las que se van a aunque no se en la tabla antes de la primera capa se realiza una transformación lda que no reduce dimensión y la función de coste a minimizar durante el entrenamiento es la función cross-entropy tal y como se en la sección trainnn también mencionar que como la dimensión de entrada de cada capa pnorm es y la de salida cada neurona dará una salida como entrada la salida de funciones de propagación la salida de cada función de propagación será utilizada por una sola neurona ambas redes utilizando parametrizaciones tanto mfcc como fmllr la cantidad de vectores de entrada a la red se constante pero la dimensión de entrada a la red esta será en el caso de los mfcc y en el caso de los vectores fmllr redes en el entorno nnet3 en el entorno de trabajo nnet3 tanto con redes tdnn como lstm con dos redes de cada tipo con las redes tdnn las funciones de activación relu y pnorm con las lstm y también con las lstm bidireccionales las especificaciones más de las redes tdnn se muestran en la tabla especificaciones de las redes tdnn nnet3 con las que se van a para la de las tdnn no es suficiente con el número de capas y la dimensión de cada capa hay que los instantes de tiempo en los que cada capa como entrada la salida de la capa anterior utilizando la misma notación en y en la figura la estructura temporal de las dos tdnn utilizadas se mediante los siguientes índices -303 -303 -303 0 el primer conjunto a la primera capa el segundo a la segunda y el a la de salida la interpretación de cada uno de los de índices se de la siguiente forma la última capa una salida correspondiente al instante el último índice es 0 para ello ésta como entrada las salidas de la capa anterior correspondientes a los instantes y de los índices cada de la capa como entrada la salida de la capa anterior en los instantes a su salida y índices -303 por ejemplo si vamos a computar la salida de la capa correspondiente al instante como entrada las salidas de la capa anterior correspondiente a los instantes y este se puede deducir la estructura temporal de las tdnn utilizadas por otra parte en la tabla se muestran las características que las lstm y utilizadas en el trabajo especificaciones de las redes lstm nnet3 con las que se van a aunque no se en la tabla antes de la primera capa se realiza una transformación lda que no reduce dimensión y la función de coste a minimizar durante el entrenamiento es la función mmi tal y como se en la sección en el caso de las redes nnet3 utilizaremos siempre vectores de parametrización mfcc entre modelos acústicos una vez descritos los modelos acústicos que se podemos las condiciones de este experimento serán las [• ]corpus para los modelos acústicos 80 los audios de todos los corpus y sus transcripciones [• ]corpus para el modelo de lenguaje transcripciones correspondientes a los audios de entrenamiento [• ]características del modelo de lenguaje modelo de lenguaje basado en trigramas con smoothing o [• ]corpus para el test 20 restante de los audios y transcripciones con estas condiciones se han entrenado y los modelos acústicos descritos en la sección los resultados wer se muestran a continuación en la tabla exp1 wer para distintos modelos acústicos entrenados con el 80 de los corpus el test se ha sobre el 20 restante utilizando un modelo de lenguaje a partir de las transcripciones de los audios de entrenamiento en la tabla exp1 se puede observar que todos los sistemas gmm-hmm basados en trifonemas han funcionado mejor que el sistema gmm-hmm basado en fonemas además en el caso de los gmm-hmm basados en trifonemas aplicar las transformaciones lda y mllt a los vectores mfcc ha resultado en una mejora del wer debido a la mayor entre clases que estas transformaciones y también al mayor contexto que en cada vector mientras que en la parametrización se tienen en cuenta vectores mfcc para computar cada vector en el caso de los vectores lda y mllt se tienen en cuenta la adaptación al hablante también ha mejorar los resultados por otro lado el rendimiento de todos los modelos híbridos ha sido mayor al de los sistemas gmm-hmm dentro de las redes correspondientes al nnet2 la red pnorm ha funcionado mejor que la red basada en la tangente hiperbólica además en ambos casos la adaptación al hablante ha a mejorar el wer siendo mayor la mejora en el caso de la red basada en la tangente hiperbólica finalmente las redes nnet3 han mejorar el wer aún más el utilizar tanto entrenamiento mediante la función de coste mmi como redes neuronales con mayor capacidad de modelizar características han a esta mejora en el rendimiento las tdnn han funcionado igual de la función de activación las redes más para el reconocimiento de voz en estas condiciones han resultado ser las dos redes lstm dada su para modelizar secuencias de vectores acústicos las lstm bidireccionales han funcionado mejor que las así que el contexto hacia la también contiene información en el del habla adaptación al hablante como se puede observar en la tabla exp1 utilizar vectores acústicos que tienen en cuenta información sobre el hablante puede ser pero también existen casos en los que adaptación puede no mejorar los resultados en la tabla se muestran los wer obtenidos para las redes nnet2 en las siguientes condiciones [• ]corpus para los modelos acústicos 80 los audios y transcripciones del corpus dihana-diálogos [• ]corpus para el modelo de lenguaje transcripciones correspondientes a los audios de entrenamiento [• ]características del modelo de lenguaje modelo de lenguaje basado en trigramas con smoothing o [• ]corpus para el test 20 restante de los audios y transcripciones de dihana-diálogos wer para distintos modelos acústicos entrenados con el corpus dihana-diálogos en la tabla podemos observar que en el caso de la red pnorm los resultados con adaptación al hablante son y la mejora en el caso de la red basada en la tangente hiperbólica es menor que en el experimento mostrado en la tabla exp1 la mejora de un a un la razón es que en el corpus de hay menos frases por hablante que si tenemos en cuenta todos los del modelo de lenguaje en el reconocimiento de voz en esta sección dos experimentos para analizar de los modelos de lenguaje en primer lugar distintos modelos de lenguaje en un experimento en el que los corpus de entrenamiento y test no después utilizaremos distintos pesos del modelo de lenguaje sobre un mismo modelo acústico experimento con distintos modelos de lenguaje las condiciones de este experimento son las siguientes [• ]corpus para los modelos acústicos 80 los audios de todos los corpus [• ]corpus para el modelo de lenguaje se tres corpus para construir distintos modelos de las transcripciones de los audios de entrenamiento de dihana-diálogos las transcripciones de los audios de entrenamiento de todos los corpus y las transcripciones de los audios de entrenamiento de todos los corpus más el país [• ]características del modelo de lenguaje modelo de lenguaje basado en trigramas con smoothing o [• ]corpus para el test 20 de los audios y transcripciones del corpus dihana-diálogos los correspondientes al test para llevar a cabo la entre modelos acústicos se sistemas gmm-hmm basados en fonemas y trifonemas y sistemas híbridos con redes neuronales correspondientes al paquete de kaldi nnet2 los resultados obtenidos se muestran en la tabla wer para tres modelos de lenguaje distintos 1 indica el correspondiente a las transcripciones de entrenamiento de dihana-diálogos 2 el correspondiente a las transcripciones de entrenamiento de todos los corpus y 3 el correspondiente a las transcripciones de entrenamiento de todos los corpus más el país como se puede en los resultados de la tabla cuanto más general es el modelo de lenguaje más le al sistema reconocer las secuencias de palabras la razón es que un modelo de lenguaje entrenado mediante secuencias de palabras a las transcripciones del test una mayor probabilidad a secuencias mientras un modelo de lenguaje general entrenado a partir de entre corpus del el país no dará probabilidad a secuencias de palabras del test que son de habla este es el caso del corpus dihana-diálogos peso del modelo de lenguaje a continuación se analizará como el rendimiento de un reconocedor de voz en función del peso del modelo de lenguaje se a cabo dos experimentos en las condiciones en la tabla condiciones en los que se van a llevar a cabo los experimentos con el peso del modelo de lenguaje los resultados de ambos experimentos se muestran en la figura en esa figura podemos que en los dos experimentos la relación del wer con el peso de modelo de lenguaje es muy distinta lo más es la del mínimo de wer en el caso de albayzin el mínimo se con un peso del modelo de lenguaje mayor que en el caso del corpus uam la razón es la siguiente: en el caso de albayzin el modelo de lenguaje se muy bien a las transcripciones del test ya que en este corpus una gran cantidad de frases de entrenamiento y test son en el caso del uam el modelo de lenguaje no es tan esta razón también que en el caso de albayzin el aumentar el peso de lenguaje no demasiado para el wer mientras que si en el caso del corpus uam nos del peso de modelo de lenguaje el wer aumenta del wer en función del peso del modelo de lenguaje realizando un test sobre el corpus uam a y albayzin b con dos modelos de lenguaje distintos del entrenamiento y rendimiento de las redes neuronales en la sección trainnn analizamos como entrenar las redes neuronales es decir como minimizar una función de coste dada para un conjunto de ejemplos de entrenamiento para ello que son un número de épocas de entrenamiento aún así no a este número en esta sección un conjunto de experimentos para que si nuestro objetivo es aumentar el rendimiento de una red neuronal existe un en el número de épocas a entrenar la red analizaremos como ese y como varía en función de la estructura de la red y de las condiciones del entrenamiento analizando la curva de entrenamiento en un caso en el que el sobre-entrenamiento entrenar durante un número de épocas no es un problema las condiciones de este experimento son las siguientes [• ]corpus para el entrenamiento 80 los audios y transcripciones del corpus dihana-diálogos [• ]características de la red neuronal se una red neuronal correspondiente al paquete nnet2 basada en la función de activación tangente hiperbólica con dos capas y neuronas por capa [• ]características del entrenamiento épocas en las el rate de forma desde hasta en las se constante en en la figura se muestran las curvas de entrenamiento para esta red con curvas de red nos a la de la función de coste en los ejemplos de entrenamiento y en un conjunto de independientes a lo largo de las épocas el conjunto de estos ejemplos independientes no utilizados para entrenar la red se datos de validación como de buena es la red neuronal que se está es decir como de buena es salidas correctas a entradas que ha curvas de entrenamiento en un caso en el que no hay sobre-entrenamiento en la figura se muestra que la función de coste en los ejemplos de entrenamiento no para de si el número de épocas aún así en los ejemplos de validación la función de coste ha un mínimo del que no en las épocas aproximadamente entrenar épocas no un problema en lo que al rendimiento de la red se pero no tiene entrenar tantas épocas si el rendimiento de la red no aumenta en las a continuación se va a un ejemplo de sobre-entrenamiento en este experimento vamos a las condiciones del anterior que la red será más con 3 capas en vez de 2 y neuronas por capa en vez de en la figura se muestra una entre los dos casos curvas de entrenamiento en dos redes que se por el número total de neuronas se pueden varias de la figura la primera es que la función de coste en el entrenamiento no que el rendimiento de la red a ser mejor un son las curvas de entrenamiento de la red con más neuronas la segunda es que las redes con un mayor número de neuronas a antes la es que la función de coste en el entrenamiento más si la red cuenta con más neuronas finalmente aunque la red con más neuronas antes es que el mínimo de la función de coste en los ejemplos de validación es menor en la red con más neuronas es decir si utilizamos el número de épocas en ambas redes la red con más neuronas mejor estos cuatro están muy relacionados con el número de parámetros libres que en cada caso para tan como el habla si utilizamos parámetros para un proceso de forma mediante una red neuronal por ejemplo es más fácil que los parámetros tan características específicas de los ejemplos con los que se ha realizado la aún así si el proceso que estamos es y el habla lo es una cantidad de parámetros demasiado pequeña no permite representar el proceso en su por ejemplo supongamos que estamos intentando modelizar la relación de un piedra en libre para calcular cuanto va a en llegar al para ello con un error la altura de dicho objeto en siete instantes de tiempo distintos ahora modelizar la relación con dos parámetros como la relación es al menos en una buena aproximación dos parámetros son para describir los siete puntos que hemos si una lineal con esos siete puntos la resultante se a los siete puntos además si deducir la del objeto en instante de tiempo en el que no hemos realizado a partir de esa no será si por el utilizamos parámetros libres una curva que se muy bien a las siete demasiado bien se tan bien que esa curva más bien el de las que el proceso que estamos intentando modelizar si deducir la de la piedra en instante de tiempo en el que no hemos realizado al igual que en el caso con 2 parámetros en el mejor caso si utilizamos 3 parámetros una curva que no por los puntos pero que para generalizar la altura del objeto en distintos instantes de tiempo este ejemplo se muestra en la figura distintas parametrizaciones de siete puntos correspondientes a la altura de una piedra en libre en distintos instantes de tiempo de acuerdo a las ecuaciones de la piedra en llegar al el modelo con dos parámetros libres que la piedra unos en el el modelo con tres parámetros libres y el modelo con parámetros libres que la piedra será por curvas de entrenamiento en una misma red para con distintas de ejemplos de entrenamiento la entre el ejemplo del objeto en libre y las redes neuronales es hemos de utilizar parámetros como para ser capaces de modelizar el proceso que estamos analizando pero no como para solo características específicas de los ejemplos de entrenamiento a continuación dos experimentos más en el primero la cantidad de ejemplos con los que entrenar la red neuronal de 3 capas y neuronas por capa del ejemplo anterior las curvas de entrenamiento para el y de los ejemplos de entrenamiento se muestran en la figura la figura es una muestra de que es más que una red neuronal menos ejemplos el sobre-entrenamiento es más con menos ejemplos de entrenamiento y el rendimiento de la red es menor el mínimo de la función de coste en los ejemplos de validación es mayor como hemos analizado utilizar un menor número de neuronas reduce el sobre-entrenamiento pero es conveniente reducir demasiado el número de neuronas porque el de que la red no sea capaz de generalizar en la figura se muestra el wer para distintos modelos acústicos obtenidos a partir de una red neuronal basada en la tangente hiperbólica con dos capas y distintos de neuronas por capa el corpus para el entrenar la red es el 80 de los audios de todos los corpus el corpus de test el 20 de los audios del corpus dihana-diálogos y el corpus para el modelo de lenguaje el 80 de las transcripciones del corpus dihana-diálogos las de entrenamiento cuanto más la cantidad total de neuronas más se el wer wer para modelos acústicos con redes con número de neuronas por capa en primer lugar en este trabajo se han las estructuras en las que se los reconocedores de voz generativos se han descrito los modelos de mezclas de gaussianas los modelos ocultos de markov las redes neuronales y también las del funcionamiento de los de estados finitos con pesos después se ha analizado como estos modelos para conseguir un reconocedor de voz de habla continua primero se han descrito distintas para una señal acústica en una secuencia de vectores que información lo más posible de la voz en segundo lugar en todo se ha que cada vector acústico ha sido por estado de un modelo de markov que cada en la mayoría de casos se han las probabilidades de emisión de cada estado de este hmm tanto con modelos de mezclas de gaussianas como con redes neuronales el rendimiento de los reconocedores basados en sistemas híbridos dnn-hmm ha al de los sistemas gmm-hmm en el caso de los sistemas gmm-hmm la más importante es que los sistemas basados en trifonemas han mostrado ser más que los sistemas basados en fonemas la razón es de forma los fonemas en función de cual ha sido el fonema anterior y de cual será es siguiente respecto a las redes neuronales los reconocedores desarrollados en este trabajo han sido los que uso de redes neuronales capaces de modelizar características de la voz en primer lugar las lstm bidireccionales por secuencias mediante la función de coste mmi han ser las más su estructura recurrente es capaz de información sobre un contexto las tdnn también han funcionado muy bien la estructura de estas redes es muy similar a las redes que en día son en el de las tdnn al igual que las redes procesan de forma igual grupos de vectores acústicos centrados en instantes diferentes así las capas más a la salida son capaces de las características independientes que las capas han finalmente entre las redes feedforward la función pnorm ha funcionado mejor que la tangente hiperbólica como función de activación la función de activación pnorm a su entrada la salida de varias funciones de propagación esta en de por y ha resultado ser también en el entorno de del habla en este trabajo también se ha analizado la del modelo de lenguaje en distintas condiciones como de al un modelo de lenguaje que una probabilidad a las transcripciones de los audios sobre los que se va a realizar un test el peso del modelo de lenguaje es mayor que en el caso de utilizar modelos de lenguaje más además la del reconocedor es menor si utilizamos modelos de lenguaje en vez de modelos de lenguaje más al tipo de habla que vamos a intentar reconocer finalmente se han realizado experimentos para analizar el entrenamiento y rendimiento de las redes neuronales respecto al entrenamiento se ha mostrado que no podemos entrenar una red neuronal al menos si queremos mejorar su rendimiento a partir de un punto la red neuronal a las características específicas de los ejemplos de entrenamiento también se ha que el sobre-entrenamiento será más cuanto mayor sea el número de neuronas de la red y menor sea la cantidad de ejemplos de entrenamiento por tanto si queremos reducir el sobre-entrenamiento una posible es reducir el número de neuronas de la red aún así como hemos reducir demasiado la cantidad de neuronas también reduce el rendimiento de la red neuronal en la cantidad de neuronas de una red ha de ser suficientemente grande como para de capacidad de generalizar a ésta pero suficientemente pequeña como para que la red no se por las características específicas de los ejemplos de entrenamiento 